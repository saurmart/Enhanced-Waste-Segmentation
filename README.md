# Masters Thesis: Enhanced Waste Segmentation Using an Electric Actuator System

<p align="center">
  <img src="https://github.com/sauermart/Enhanced-Waste-Segmentation/assets/67053833/ce8e81b8-996e-48bb-b937-f3954d952164" width="400" height="400"/> <img src="https://github.com/sauermart/Enhanced-Waste-Segmentation/assets/67053833/ce8e81b8-996e-48bb-b937-f3954d952164" width="400" height="400"/>
</p>

The Enhanced Waste Segmentation datasets can be found [here](https://mega.nz/folder/xPsyFSqC#2pAHInj2InZvIsG52Wwp_Q).

## Abstract

The rise in global waste production presents a significant threat to both people and the environment. To combat this issue, it is necessary to implement resource-friendly waste separation and efficient recycling of recyclable materials. The utilization of convolutional neural networks shows great potential, particularly for separating various types of waste. However, recent developments indicate that state-of-the-art object segmentation models are insufficient in dealing with the complexity and diversity of recycling waste. This thesis presents a low-cost electric actuator system (EAS) in the form of a vibration plate. Additionally, a waste segmentation dataset is created to train, validate, and test two Mask R-CNN and two YOLOv8 segmentation models with varying specifications. The dataset comprises 947 manually annotated images, with 22,630 annotated objects belonging to cardboard, hard plastic, metal, and soft plastic classes. It was augmented using various techniques and enriched with complexity, resulting in 5,716 images and 137,324 annotated instances. The vibration generated by the EAS was effective in separating waste objects of different materials to a significant extent. This resulted in an increase in the mean average precision for segmentation mask 
mAP<sup>mask</sup> of a Mask R-CNN model with R101-FPN-3x backbone from 26.5% to 60.9%. The other models also demonstrated a significant improvement in mAP<sup>mask</sup>: Mask R-CNN R50-FPN-1x (24.4% to 58.8%), pre-trained YOLOv8 nano (24.9% to 50.6%) and non-pre-trained YOLOv8 nano (20.2% to 51.1%). It has been confirmed that the use of EAS improves the results of convolutional neural networks. In the future, this system could be used as a sub-process in automated waste separation.

## Experiments
The training and evaluation was conducted on an NVIDIA Tesla T4 with 16 GB of memory provided by Google Colab

### YOLOv8 implementation

#### Requirements

- [Ultralytics](https://github.com/ultralytics/ultralytics) version
- Python version 3.10.12
- Torch version 2.1.0
- CUDA version 11.2.1

#### Training and Evaluation

- pre-trained YOLOv8 seg: ```Hier kann der Code stehen, wenn man weiß, wie man ihn schreibt ```
- non-pre-trained YOLOv8 seg: ```Hier kann der Code stehen, wenn man weiß, wie man ihn schreibt ```

### Mask R-CNN implementation

#### Requirements

- [Detectron2](https://github.com/facebookresearch/detectron2) version 0.6, available on GitHub,
- Python version 3.10
- Torch version 2.1.0
- CUDA version 12.2.140

#### Training and Evaluation

- Mask R-CNN R50-FPN-1x: ```Hier kann der Code stehen, wenn man weiß, wie man ihn schreibt ```
- Mask R-CNN R101-FPN-3x: ```Hier kann der Code stehen, wenn man weiß, wie man ihn schreibt ```

